---
layout: post
title: 'Markov Chains – Explained | Tech Effigy'
url: http://techeffigy.wordpress.com/2014/06/30/markov-chains-explained/
source: http://techeffigy.wordpress.com/2014/06/30/markov-chains-explained/
domain: techeffigy.wordpress.com
image: 
---

<p>Markov Chains is a probabilistic process, that relies on the current state to predict the next state.For Markov chains to be effective the current state has to be dependent on the previous state in some way; For instance, from experience we know that if it looks cloudy outside, the next state we expect is rain.We can also say that when the rain starts to subside into cloudiness, the next state will most likely be sunny.Not every process has the Markov Property, such as the Lottery, this weeks winning numbers have no dependence to the previous weeks winning numbers.Usually when we have data, we calculate the probability of a state by counting the amount of times it occurs within a total of all states, we then end up with 0.</p>
<center><p><a href="http://techeffigy.wordpress.com/2014/06/30/markov-chains-explained/" style='padding:25px; font-sze:18px; font-weight: bold;'>Read Full Story</a></p></center>
